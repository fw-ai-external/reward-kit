# Hydra Configuration for examples/math_example/trl_grpo_integration.py

hydra:
  run:
    dir: ./outputs/trl_grpo_math/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job_logging:
    root:
      level: INFO

# Path to the processed dataset file (JSONL format) for TRL training
# This path can be relative to the original CWD or absolute.
dataset_file_path: "dataset.jsonl" # Default, assumes dataset.jsonl is in the same dir as the script

# Model and output directory (can be overridden)
model_name: "Qwen/Qwen2-0.5B-Instruct"
# output_dir: "math_grpo_trainer_output_qwen" # Hydra will manage output directory by default

# GRPOConfig settings (can be expanded)
# For now, these are mostly kept in the script, but could be moved here.
grpo:
  learning_rate: 1.41e-5
  beta: 0.1
  num_train_epochs: 1
  max_steps: 5 # Set to 1 if TEST_MODE_TRL=true in script
  logging_steps: 1
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 1
  # remove_unused_columns: False # This is set in script, important
  # no_cuda: false # This is set in script based on TEST_MODE_TRL
  max_completion_length: 50
  top_k: 0.0
  top_p: 1.0
  do_sample: True

# Test mode flag (can be set via command line: +test_mode_trl=true)
test_mode_trl: false
